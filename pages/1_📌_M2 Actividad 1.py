import sqlite3
import numpy as np
import pandas as pd
import firebase_admin
import streamlit as st
from pymongo import MongoClient
from firebase_admin import credentials
from firebase_admin import firestore
from sqlalchemy import create_engine

#Crea una aplicaciÃ³n bÃ¡sica en Streamlit:
st.set_page_config(   
    page_icon="ğŸ“–",
    layout="wide"
)

st.title("Momento 2 Â° Actividad 1")

st.markdown(""" """)

st.header("ï½¥ï¾Ÿâœ§ï¼CreaciÃ³n de DataFrames .âœ§ï½¥ï¾Ÿ")
st.subheader("DescripciÃ³n de la actividad")
# DescripciÃ³n general
st.write("""
    En esta actividad, vamos a explorar diferentes formas de crear **DataFrames** en Pandas
    y mostrarlos utilizando Streamlit. A continuaciÃ³n, se presentan varios tipos de DataFrames:
    - Diccionario de libros
    - Lista de diccionarios con informaciÃ³n de ciudades
    - Lista de listas con productos
    - Series combinadas para personas
    - Datos cargados desde un archivo CSV como:
        - CSV (local)
        - Excel (local)
        - Archivo JSON
        - URL
    - Base de datos SQLite
    - Array de NumPy
    - Firebase
    - MongoDB
         
""")

#----------------------------------------------------------------------
st.markdown(""" """)
#Crea DataFrames desde diferentes fuentes:

# Diccionario de libros
libros = {
    "tÃ­tulo": ["Cien aÃ±os de soledad", "Don Quijote de la Mancha", "1984", "El amor en los tiempos del cÃ³lera"],
    "autor": ["Gabriel GarcÃ­a MÃ¡rquez", "Miguel de Cervantes", "George Orwell", "Gabriel GarcÃ­a MÃ¡rquez"],
    "aÃ±o de publicaciÃ³n": [1967, 1605, 1949, 1985],
    "gÃ©nero": ["Realismo mÃ¡gico", "Novela de caballerÃ­a", "DistopÃ­a", "RomÃ¡ntico"]
}

df_libros = pd.DataFrame(libros)

st.subheader(".âœ§ï½¥ï¾Ÿ ğŸ“š DataFrame de Libros ğŸ“š ï½¥ï¾Ÿâœ§ï¼")
st.write("A continuaciÃ³n se muestra un DataFrame con informaciÃ³n sobre algunos libros.")
st.dataframe(df_libros)


#----------------------------------------------------------------------
st.markdown(""" """)
# Lista de diccionarios
ciudades = [
    {"nombre": "BogotÃ¡", "poblaciÃ³n": 8000000, "paÃ­s": "Colombia"},
    {"nombre": "Lima", "poblaciÃ³n": 9000000, "paÃ­s": "PerÃº"},
    {"nombre": "Madrid", "poblaciÃ³n": 3200000, "paÃ­s": "EspaÃ±a"},
    {"nombre": "Buenos Aires", "poblaciÃ³n": 3000000, "paÃ­s": "Argentina"}
]

df_ciudades = pd.DataFrame(ciudades)

st.subheader(".âœ§ï½¥ï¾ŸğŸŒInformaciÃ³n de Ciudades ğŸŒï½¥ï¾Ÿâœ§ï¼")
st.write("Este es un DataFrame que muestra algunas ciudades, su poblaciÃ³n y el paÃ­s al que pertenecen.")
st.dataframe(df_ciudades)

#----------------------------------------------------------------------
st.markdown(""" """)
# Lista de listas de productos
productos = [
    ["Tablet", 350.00, 12],
    ["Auriculares", 80.50, 40],
    ["Cargador", 25.00, 100],
    ["Smartwatch", 200.00, 15]
]

df_productos = pd.DataFrame(productos, columns=["Producto", "Precio", "Stock"])

st.subheader(".âœ§ï½¥ï¾ŸğŸ›ï¸ Productos en Inventario ğŸ›ï¸ï½¥ï¾Ÿâœ§ï¼")
st.write("AquÃ­ mostramos algunos productos, su precio y la cantidad disponible en stock.")
st.dataframe(df_productos)


#----------------------------------------------------------------------
st.markdown(""" """)
# Series de personas
nombres = pd.Series(["Ana", "Luis", "MarÃ­a", "Carlos"])
edades = pd.Series([28, 34, 22, 30])
ciudades = pd.Series(["BogotÃ¡", "Lima", "Madrid", "Buenos Aires"])

# Combinar en un diccionario
personas = {
    "nombre": nombres,
    "edad": edades,
    "ciudad": ciudades
}

df_personas = pd.DataFrame(personas)

st.subheader(".âœ§ï½¥ï¾ŸğŸ‘¥ Datos de Personas ğŸ‘¥ï½¥ï¾Ÿâœ§ï¼")
st.write("A continuaciÃ³n se muestra informaciÃ³n sobre varias personas, incluyendo su nombre, edad y ciudad.")
st.dataframe(df_personas)


#----------------------------------------------------------------------
st.markdown(""" """)
df_csv = pd.read_csv('static/datasets/data.csv')
st.subheader(".âœ§ï½¥ï¾ŸğŸ“„ Datos desde CSV ğŸ“„ï½¥ï¾Ÿâœ§ï¼")
st.write("AquÃ­ estÃ¡n los datos cargados desde un archivo CSV.")
st.dataframe(df_csv)

#----------------------------------------------------------------------
st.markdown(""" """)
# Archivo Excel (local):
st.subheader(".âœ§ï½¥ï¾ŸğŸ“— Datos desde un archivo excel ğŸ“—.âœ§ï½¥ï¾Ÿ")
st.write("AquÃ­ estÃ¡n los datos cargados desde un archivo de excel, muestra el id, nombre y apellido de personas")
df_excel = pd.read_excel('static\datasets\Alumnos.xlsx')
st.dataframe(df_excel)


#----------------------------------------------------------------------
st.markdown(""" """)
# Archivo JSON
st.subheader(".âœ§ï½¥ï¾ŸğŸ—‚ï¸ Datos desde un json ğŸ—‚ï¸âœ§ï½¥ï¾Ÿ")
st.write("AquÃ­ estÃ¡n los datos cargados desde un json, muestra los nombres, la edad y la cuidad a la que pertenecen")
df_json = pd.read_json("static\datasets\data.json")
st.dataframe(df_json)

#----------------------------------------------------------------------
st.markdown(""" """)
# URL:
st.subheader(".âœ§ï½¥ï¾ŸğŸŒ Datos desde una URL ğŸŒâœ§ï½¥ï¾Ÿ")
st.write("A continuaciÃ³n se muestra informaciÃ³n sobre usuarios")
df_Url = pd.read_csv("https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv")
st.dataframe(df_Url)


#----------------------------------------------------------------------
st.markdown(""" """)
# Conectar a la base de datos SQLite
conn = sqlite3.connect("estudiantes.db")
df = pd.read_sql("SELECT * FROM notas", conn)
conn.close()

# Mostrar los datos
st.subheader(".âœ§ï½¥ï¾ŸğŸ§® Datos desde SQLite ğŸ§®.ï½¥ï¾Ÿâœ§")
st.dataframe(df)


#----------------------------------------------------------------------
st.markdown(""" """)
#Array de NumPy:
st.subheader(".âœ§ï½¥ï¾ŸğŸŸ¦ Datos desde NumPy ğŸŸ¦.ï½¥ï¾Ÿâœ§")

# Creamos una matriz de 3 filas y 2 columnas
datos = np.array([
    ["Ana", 85, "desarrollo de software" ],
    ["Luis", 92, "desarrollo de software"],
    ["Carlos", 78, "desarrollo de software"]
])

# Convertimos a DataFrame y ponemos los nombres de columnas
df_NumPy = pd.DataFrame(datos, columns=["Nombre", "Calificacion", "Curso"])

st.dataframe(df_NumPy)

#----------------------------------------------------------------------
st.markdown(""" """)
#Firebase --> IMPORTANTE (antes de subir algun commit se debe colocar en gitignore --> static/datasets/key.json)
# consola > pip install firebase-admin pandas
# configurar API https://console.cloud.google.com/apis/api/firestore.googleapis.com/metrics?project=entregables-python-a6527
#configurar iniciar BD https://console.cloud.google.com/datastore/create-database?project=entregables-python-a6527
st.subheader(".âœ§ï½¥ï¾ŸğŸ‚ Datos desde FirebaseğŸ‚.ï½¥ï¾Ÿâœ§")

# Inicializar solo una vez
if not firebase_admin._apps:
    cred = credentials.Certificate('static\datasets\key.json')
    firebase_admin.initialize_app(cred)

db = firestore.client()

# Obtener datos (llamar una coleccion)
users = db.collection('Univercidad').stream()
users_data = [doc.to_dict() for doc in users]
df = pd.DataFrame(users_data)

st.dataframe(df)

#----------------------------------------------------------------------
# Conectar a MongoDB Atlas
# consola --> pip install pymongo
client = MongoClient("mongodb+srv://SkarletUser:genessiskarlet@mi-cluster.r5118qf.mongodb.net/")
db = client["sample_mflix"]             
coleccion = db["comments"]                

# Traer documentos (limitamos a 100)
documentos = list(coleccion.find().limit(100))

# Convertir a DataFrame 
df = pd.DataFrame(documentos)

# Mostrar en Streamlit
st.subheader(".âœ§ï½¥ï¾ŸğŸƒ Datos desde MongoDB ğŸƒ.ï½¥ï¾Ÿâœ§")
st.dataframe(df)    